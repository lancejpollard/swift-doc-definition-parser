{
  "path": "/documentation/accelerate/bnnsoptimizerfunction",
  "type": "Structure",
  "name": "BNNSOptimizerFunction",
  "desc": "A structure that contains optimizer functions.",
  "items": [
    {
      "name": "var BNNSOptimizerFunctionAdamW: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the AdamW algorithm."
    },
    {
      "name": "var BNNSOptimizerFunctionAdamWWithClipping: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the AdamW algorithm and optionally clips the gradient by value or by norm."
    },
    {
      "name": "var BNNSOptimizerFunctionAdamWAMSGrad: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm."
    },
    {
      "name": "var BNNSOptimizerFunctionAdamWAMSGradWithClipping: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm and optionally clips the gradient by value or by norm."
    },
    {
      "name": "var BNNSOptimizerFunctionRMSProp: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the root mean square propagation (RMSProp) algorithm."
    },
    {
      "name": "var BNNSOptimizerFunctionRMSPropWithClipping: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the root mean square propagation (RMSProp) algorithm and optionally clips the gradient by value or by norm."
    },
    {
      "name": "var BNNSOptimizerFunctionSGDMomentum: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the stochastic gradient descent (SGD) with momentum algorithm."
    },
    {
      "name": "var BNNSOptimizerFunctionSGDMomentumWithClipping: BNNSOptimizerFunction",
      "desc": "An optimizer function that updates parameters according to the stochastic gradient descent (SGD) with momentum algorithm and optionally clips the gradient by value or by norm."
    },
    {
      "name": "var rawValue: UInt32"
    },
    {
      "name": "init(UInt32)"
    },
    {
      "name": "init(rawValue: UInt32)"
    }
  ],
  "declaration": "struct BNNSOptimizerFunction",
  "conformsTo": [
    "Equatable",
    "RawRepresentable"
  ]
}